Nom du fichier: IPM1481.pdf

Titre: 

Auteurs: 

Automatic summarization is useful to cope with ever increasing volumes of information. An abstract is, by far, the mostconcrete and recognized kind of text condensation. However, the CV is already a kind of summary, with a very importantstructure. We suspect that the filtering system of automatic summarization may not be useful in this case. Since the CL isin free text, we used CORTEX (Torres-Moreno, St-Onge, Gagnon, El-Bèze, & Bellot, 2009, 2001), an efficient state-of-art summa-rization system, in order to retain the more informative segments of the CL.Each document of the application is transmitted to the CORTEX system which provides a summary based on the requestedsize. CORTEX is a document extract summarization system using an optimal decision algorithm that combines several metrics.These metrics result from processing statistical and informational algorithms on the document vector space representation.Fig. 2 presents an overview of the system.The idea is to represent the text in an appropriate vectorial space and apply numeric processings to it. In order to reducecomplexity, a pre-processing of the document is performed: words are filtered, lemmatized, and stemmed. Based on theterms that remain in the text after filtering, a frequency matrix c is built in the following way: Each element cli of this matrixrepresents the number of occurrences of the word i in the sentence l.13 JobFinder (http://www.jobfinder.com).1128R. Kessler et al. / Information Processing and Management 48 (2012) 1124–1135Author's personal copyc ¼c11c12. . .c1i. . .c1NLc21c22. . .c2i. . .c2NL..................cl1cl2. . .cli. . .clNL..................cNS1cNS2. . .cNSi. . .cNSNL2666666666666437777777777775;cli 2 f0; 1; 2; . . .gð5ÞAnother matrix n, called a binary virtual or presence matrix, is defined as:nli ¼1if cli – 00elsewhere()ð6ÞEach line of these matrices represents a sentence of the text. Matrices c and cT are the frequency matrix of the sentencesand frequency matrix of the titles respectively.The CORTEX system can use up to C = 11 metrics (Torres-Moreno, Velazquez-Morales, & Meunier, 2002) to evaluate the sen-tence’s relevance.The system scores each sentence with a decision algorithm which relies on the normalized metrics. Two averages are cal-culated, a positive ks > 0.5, and a negative ks < 0.5 tendency (the case ks = 0.5 is ignored). The following algorithm combinesthe vote of each metric:Ps a ¼ PCv¼1kvs���� � 0:5��;kvs���� > 0:5Psb ¼ PCv¼10:5 � kvs������;kvs���� < 0:5Cis the number of metrics and v is the index of the metrics. The value given to each sentence s is calculated with:ifPs a > Psb��then Scorecortexs¼ 0:5 þ Psa=C: retain selse Scorecortexs¼ 0:5 � Psb=C: not retain sFig. 2. CORTEX overview.R. Kessler et al. / Information Processing and Management 48 (2012) 1124–11351129Author's personal copyThe sentences are then ranked according to the obtained values. Depending on the desired compression rate, the sortedsentences will be used to produce the summary. The CORTEX system is applied to each document (Cover Letter) and a sum-mary is generated by concatenating high-scoring sentences. We generated several abstracts with a variable compression rate(5%, 10%, 20%, . . ., 50%, 75% of the size of the documents, in sentences) in order to test the impact of our powerful filter on theE-Gen system. The entire process chain is illustrated in Fig. 1. The best compression rates are generally with 30% (Torres-Moreno et al., 2009). The results are presented in Section 5.3.5. ExperimentsWe selected a data subset from Aktor’s database composed of 1917 candidates. This subset is called the Mission Corpus. Ithas a size of 10 MB of raw texts and contains 1,375,000 words. The Mission Corpus is composed of a set of 12 job offers cov-ering various themes (jobs in accountancy, business, computer science, etc.) and their candidates. Each Job Offer is associatedwith at least six candidates identified as relevant. As described in Kessler et al. (2008a), each document is segmented to keepthe relevant parts (we remove the description of the company (D) for the job offer). Each candidate answer is tagged as rel-evant or irrelevant. A relevant value corresponds to a potential candidate for a specific job chosen by the recruiting consul-tant. An irrelevant value is associated with an unsuitable candidate for the job (this is a decision made by the manager of ahuman resources company). Our study was conducted on French job offers because the French market represents Aktor’smain activity. Table 1 shows a few statistics about the Mission Corpus.5.1. Example of CL summariesFig. 3 presents14 an example of an original Cover Letter and Fig. 4. Its corresponding summary15generated by the CORTEX sys-tem with a 30% compression rate (in number of sentences).All the documents of Mission Corpus were previously made anonymous. We observe that the original CL contains anumber of useless information for ranking, such as addresses, phone numbers or form of address at the beginning orend of the letter. The last part of the CL is generally as ‘‘Yours faithfully’’, ‘‘Yours sincerely’’, ‘‘Best regards’’, all of whichrepresent irrelevant information. We further observe in Fig. 4 that the summary obtained with CORTEX removes all thisinformation.5.2. Experimental protocolWe measured the similarity between a job offer and its candidate’s responses. These measures (Section 4.1.2) rank thecandidate’s answers by computing a similarity between a job offer and the associated candidate answers. We use theROC curves to evaluate the quality of the ranking obtained. ROC curves (Ferri, Flach, & Hernandez-Orallo, 2002) come fromthe field of signal processing. They are used in medicine to evaluate the validity of diagnostic tests. In our case, ROC curvesshow the rate of irrelevant candidate answers on the X-axis and the rate of relevant candidate answers on the Y-axis. The14 Pierre ASPRE26 years old19 Verdun street 92870 Vannes06-06-06-06-06.Subject: collaboration offerVannes, November 27th, 2008Dear Sir,The Accountant is a key player not only for the proper functioning of the enterprise, but also in increasing profitability. With his legal knowledge in taxand social issues, he can make substantial savings: he is a key player for maintaining a cash reserve by ensuring the payment of customer invoices andknowing how to deal with the late settlement of invoices.Therefore I offer my skills. They allow me to:– Manage with rigueur the accounts of a company.– Ensure legal compliance activities (payroll, tax billing etc.).– Provide advice particularly important in times of assessment, all thanks to my seriousness, my strength and my analysis.I suggest we meet to discuss all the terms of our future cooperation.I look forward to hearing from you.Best regards.Pierre ASPRE.15 Pierre ASPRESubject: collaboration offerThe Accountant is a key player not only for the proper functioning of the enterprise, but also in increasing profitability. With his legal knowledge in taxand social issues, he can make substantial savings: he is a key player for maintaining a cash reserve by ensuring the payment of customer invoices andknowing how to deal with late settlement of invoices.– ensure legal compliance activities (payroll, tax billing etc.).– provide advice particularly important in times of assessment, all thanks to my seriousness, my strength and my analysis.1130R. Kessler et al. / Information Processing and Management 48 (2012) 1124–1135Author's personal copyArea Under the Curve (AUC) can be interpreted as the effectiveness of a measurement of interest. In the case of candidateanswers ranking, a perfect ROC curve corresponds to obtaining all relevant candidate answers at the beginning of the listand all irrelevant ones at the end. This situation corresponds to AUC = 1. The diagonal line corresponds to the performanceof a random system, progress of the rate of relevant candidates being accompanied by an equivalent degradation in the rateof irrelevant candidates. This situation corresponds to AUC = 0.5, as explained in Fawcett (2006). An effective measurementFig. 3. Example of full Cover Letter.Table 1Mission corpus statistics.NumberJob titleNumber of candidate answersNumber ofRelevantIrrelevant34861Sales engineer40142631702Accountant, department suppliers55233233633Sales engineer65184734865Accountant assistant67105734783Accountant assistant108999337463 chefs116605633553Trade commissioner1171710033725Urban sales consultant118437531022Recruitment assistant2212819331274Accountant assistant junior2242619834119Sales assistant2571024731767Accountant assistant junior43751386Total19173231594Fig. 4. Summary of Cover Letter (see Fig. 3) at a 30% compression rate.R. Kessler et al. / Information Processing and Management 48 (2012) 1124–11351131Author's personal copyof interest to order candidate’s answers consists in obtaining the highest AUC value. This is strictly equivalent to minimizingthe sum of the ranks of the relevant candidate’s answers. ROC curves are resistant to imbalance (for example, an imbalancein the number of positive and negative examples) (Roche & Kodratoff, 2006). For each job offer, we evaluated the quality ofthe ranking obtained by this method. Candidate answers considered are only those composed of CV and CL.5.3. ResultsIn this section, we present the results obtained by combining the CORTEX system with the E-Gen ranking application. CORTEXwas used as an additional filter which generates a summary of each document before E-Gen evaluation. We keep the struc-ture of data for job offers as described in Kessler et al. (2008a). A job offer is composed of a Description (D), a Title (T), aMission (M), and a Profile (P). For these experiments, we use two combinations of a job offer content, keeping only Title, Mis-sion, Profile (TMP) and all information of a job offer (DTMP). Results are presented in Tables 2 and 3. Each column presents apart of the application with different sizes of summaries for each line (75%, 50%, . . ., 5%). Full text is a result obtained with100% of the document and was published previously in Kessler et al. (2008a, 2009).Table 2 presents results obtained for each part of the application separately. We observe that AUC of CVs remains belowthe baseline whatever the percentage of compression. We notice however a gradual decrease in AUC scores depending on thepercentage of compression. We explain this by the fact that a CV is already a summary of the most important informationabout the candidates and thereby attempting to summarize degrades final results. We apply the same process with coverletters. Performance is still low overall for CLs in comparison with CVs, however, there is a slight increase in AUC scores witha compression rate of 30%. We explain these results by particular information contained in a cover letter such as the form ofaddress at the beginning or end of the letter (see Fig. 4) which are noise for the ranking system of E-Gen. Results with TMPsegmentation (i.e. conserving only Title, Mission, and Profile of job offer) are of better quality.Table 3 presents the results obtained by combining both parts of the application. Full text values are computed with thewhole documents of the application. The first two columns show the results obtained by combining the summary of the CVand the CL. We observe again a deterioration in the results when trying to summarize the CV. Even if results are lower, itshould be noted, however, that the best score is again obtained at 30%. The last two columns present the results with a sum-marized CL and the full CV. We observe an overall improvement of the AUC score and the best results with a compressionrate of 30% of the Cover Letter.Next step is to combine summaries of the cover letter, which suppresses noise and enriches the offer with the RelevanceFeedback process. Table 4 presents the results obtained with different sizes of Relevance Feedback (RF1 corresponds to oneapplication added to the job offer, RF2 two applications added to the job offer, etc.). Each application added with the rele-vance feedback process consists in a full CV and a summary of the cover letter with a compression rate of 30%. A randomdistribution of applications produces an AUC approximately at 0.5 like explained in Fawcett (2006). We compare ISMIS Resultwith those obtained using a summary of the cover letter. Each test is carried out 100 times with a random distribution ofrelevant applications for Relevance Feedback. Then we compute an average of AUC scores obtained (the curve shows theTable 2Results of CL or CV according to the compression rate of Cortex and part of job offer (with or without Description part).CORTEX compression rate (%)CV + DTMPCV + TMPCL + DTMPCL + TMP100 (full text)0.6220.6480.5670.560750.5650.5750.5630.556500.5580.5690.5530.560400.5520.5650.5610.565300.5490.5600.5690.571200.5200.5580.5640.566100.5590.5590.5430.55450.5500.5420.5210.523Table 3Results for CV and cover letter according to the compression rate.CORTEX compression rate (%)CV and CL summariesFull CV and CL summaryDTMPTMPDTMPTMP100 (full text)0.6340.6420.6340.642750.5210.5810.6390.641500.5560.5510.6430.649400.5440.5680.6430.651300.5700.5870.6460.653200.5690.5330.6410.652100.5640.5340.6310.64550.5460.5470.6380.6491132R. Kessler et al. / Information Processing and Management 48 (2012) 1124–1135Author's personal copyaverage for each size). In fact, we compute the Residual Ranking (Billerbeck & Zobel, 2006): Documents that are used for Rel-evance Feedback are removed from the collection before ranking with the reformulated query. We assume that the Rele-vance Feedback process would behave as a reinforcement learning (Sutton & Barto, 1998) but it is impossible toexperiment RFn with n > 6 with this corpus because the number of relevant candidates is too small for some job offers(see Table 1). We observe a slight improvement in results for almost any size of Relevance Feedback. We are conscious thatthe performance gain is low, however, it confirms previous results on the Cover Letter. Fig. 5 shows this improvement. Thisfigure confirms that the addition of just one relevant candidate (RF1) enables the AUC value to be enhanced (i.e. an improve-ment of 0.5–1.2%). This Relevance Feedback (i.e. RF1) is not very time-consuming for the expert.Fig. 6 shows detailed results of one test. For clarity reasons, we present only 3 of the 12 jobs of our dataset in order tocompare results with and without CORTEX (for each job, RFC are AUC scores with CORTEX and RF without CORTEX).For standard system, we observe a positive progress from 1% to 10% for 10 jobs between RF0 and RF1 (e.g. five jobs havean improvement between 5% and 10%). Note that between RF0 and RF6, 6 jobs have a significant positive progress between10% and 12%. The combination of the E-Gen and CORTEX systems improve standard system results for five jobs from 1% to 5%between RF0 and RF1. Between RF0 and RF6, the Cortex version improves E-Gen’s results for eight jobs from 1% to 5%.The study of the results shows that job offer 31702 contains some relevant applications with a bad labeling (CV are la-beled CL and CL are only a hyperlink to a CV). The reduction of information on the main document of the application leadsthe system version using summaries to degrade the AUC scores. Job offer 34861 shows a good improvement with each size ofrelevance feedback (RF0:0.65, RF1:0.70, RF6:0.73) and with CORTEX (RF0:0.68, RF1:0.72, RF6:0.79). The detailed study of re-sults shows that job offer 33746 contains some empty applications labeled relevant. This leads the system with and withoutCORTEX to degrade final results. In the same way, an application added without CL explains the identical score in RF2 betweenRF and RFC for job offer 31274.6. Conclusion and future workJob offer processing is a difficult and highly subjective task. The retrieval of relevant information concerning job descrip-tions and skills is not a trivial task (Loth et al., 2010) and results on this type of document have been quite low (Clech &Table 4Comparison of AUC score for each size of Relevance Feedback with CORTEX summarization system.Size of Relevance FeedbackISMIS resultFull CV and CL summary 30% compression rateRandom distribution0.5000.500RF00.6420.653RF10.6540.658RF20.6570.659RF30.6590.661RF40.6590.659RF50.6600.662RF60.6610.663Fig. 5. Results of Relevance Feedback with and without summaries of CL.R. Kessler et al. / Information Processing and Management 48 (2012) 1124–11351133Author's personal copyZighed, 2003). The information we use in this kind of process is not well formated in natural language, but follows a conven-tional structure. This paper deals with the CORTEX summarizer and the E-Gen system for processing job offers. E-Gen assists anemployer in the recruitment task. This paper focuses on candidate answers to job offers. We rank the candidate answers byusing different similarity measures and different document representations in a vector space model. We use a process of rel-evance feedback to perform reinforcement learning, whereby each new application added to the process assists in the deci-sion-making. We choose to evaluate the quality of our approaches by computing Area Under the Curve.CORTEX is asummarization system using an optimal decision algorithm that combines several metrics. We present the results obtainedby combining both systems. AUC obtained with summarized cover letter at 30% of compression size and a full CV shows aslight improvement in the results. As future work, we plan to apply other techniques, such as finding discriminant features ofirrelevant applications using the Rocchio algorithm (Rocchio, 1971), weighting the different parts of an application, etc. inorder to improve results. We also plan to use a categorization of jobs to take into consideration similar jobs, such as ’’devel-oper’’ and ‘‘programmer’’. Finally we propose to measure the CV quality by building an evaluation on an Internet portal. Ouraim with this evaluation is to present a job-seeker with a list of the most suitable job ads according to his profile.AcknowledgementsAuthors thank Richard James, Véronique Moriceau, André Bittar, ANRT (Agence Nationale de la Recherche Technologique)and Aktor Interactive that partially supported this work.ReferencesAudras, I., & Ganascia, J.-G. (2006). Apprentissage du frantais langue TtrangFre et TALN: Analyses de corpus Tcrits a l’aide d’outils d’extraction automatiquedu langage. In J.-M. Viprey (Ed.), 8Fmes JournTes d’Analyse de DonnTes Textuelles (pp. 67–78). Univ. de Franche ComtT, Besanton 2006.Bellot, P., & El-Bèze, M. (2001). Classification et segmentation de textes par arbres de dTcision. In TSI (Vol. 20, pp. 107–134). HermFs.Ben Abdessalem Karaa, W. (2009). Web-based recruiting: A framework for cvs handling. In Second international conference on web and informationtechnologies ‘‘ICWIT’09’’, kerkennah Island, Sfax, Tunisia, June 12–14 (pp. 395–406).Bernstein, A., Kaufmann, E., Kiefer, C., & Bnrki, C. (2005). Simpack: A generic java library for similarity measures in ontologies. Tech. rep., University of ZurichDepartment of Informatics.Billerbeck, B., & Zobel, J. (2006). Efficient query expansion with auxiliary data structures. Information Systems, 31(7), 573–584.Boudin, F., & Torres Moreno, J. M. (2007). Neo-cortex: A performant user-oriented multi-document summarization system. In CICLing (pp. 551–562).Bourse, M., LeclFre, M., Morin, E., & Trichet, F. (2004). Human resource management and semantic web technologies. In ICTTA 2004 Damascus Syria (pp. 641–642).Cazalens, S., & Lamarre, P. (2001). An organization of internet agents based on a hierarchy of information domains. In Proceedings MAAMAW’2001, Annecy,France (pp. 573–584).Clech, J., & Zighed, D. A. (2003). Data mining et analyse des cv: une expérience et des perspectives. In EGC’03 Revue des Sciences et Technologies del’Information (Vol. 17, pp. 83–92). Lyon.Colucci, S., Di Noia, T., Di Sciascio, E., Donini, F. M., Mongiello, M., & Mottola, M. (2003). A formal approach to ontology-based semantic match of skillsdescriptions. Journal of Universal Computer Science, Special issue on Skills Management, 9, 1437–1454.Dorn, J., & Naz, T. (2007). Meta-search in human resource management. In Proceedings of 4th international conference on knowledge systems ICKS’07Bangkok,Thailand (pp. 105–110).Enrica, A., & Iezzi, D. F. (2006). Recruitment via web and information technology: A model for ranking the competences in job market. In JADT’2006,Besanton, France (pp. 79–88).Fan, R.-E., Chen, P.-H., & Lin, C.-J. (2005). Working set selection using the second order information for training SVM. Journal of Machine Learning Research,1889–1918.

Introduction : Ferri, C., Flach, P., & Hernandez-Orallo, J. (2002). Learning decision trees using the area under the ROC curve. In Proceedings of ICML 2002: Sydney, NSW,Australia (pp. 139–146).Gorenak, I., & Mlaker KaF, S. S. O. (2010). Cross-cultural comparison of online job advertisements. JLST, Journal of Logistics and Sustainable Transport, 2, 37–52.RF0RF1RF2RF3RF4RF5RF60,400,450,500,550,600,650,700,750,800,85AUC scoreRelevance Feeback size 34861 RF 34861 RFC 31274 RF 31274 RFC 31702 RF 31702 RFCFig. 6. Comparison of detailed results for 3 jobs with and without summaries of CL. For each job, RFC means AUC scores with CORTEX and RF without CORTEX.1134R. Kessler et al. / Information Processing and Management 48 (2012) 1124–1135Author's personal copyJoachims, T. (1997). A probabilistic analysis of the rocchio algorithm with tfidf for text categorization. In ICML 1997, Nashville, Tennessee, USA (pp. 143–151).San Francisco, CA, USA.Kessler, R., Béchet, N., Roche, M., El-Bèze, M., & Torres-Moreno, J. M. (2008a). Automatic profiling system for ranking candidates answers in humanresources. In OTM ’08 in Monterrey, Mexico (pp. 625–634).Kessler, R., Béchet, N., Roche, M., El-Bèze, M., & Torres-Moreno, J. M. (2009). Job offer management: How improve the ranking of candidates. Prague: ISMIS.431–441.Kessler, R., Torres-Moreno, J. M., & El-Bèze, M. (2007). E-Gen: Automatic job offer processing system for human ressources. In MICAI, Aguscalientes, Mexique(pp. 985–995).Kessler, R., Torres-Moreno, J. M., & El-Bèze, M. (2008b). E-Gen: Profilage automatique de candidatures. In TALN 2008, Avignon, France (pp. 370–379).Loth, R., Battistelli, D., Chaumartin, F., De Mazancourt, H., Minel, J. L., & Vinckx, A. (2010). Linguistic information extraction for job ads (SIRE project). InRIAO’2010 9th conference 28–30 April, Paris, France (pp. 300–303).Marchal, E., Mellet, K., & Rieucau, G. (2007). Job board toolkits: Internet matchmaking and changes in job advertisements. Human Relations, 60(7),1091–1113.Mocho, M., Paslaru, E., & Simperl, B. (2006). Practical guidelines for building semantic e-recruitment applications. In I-Know’06 special track on advancedsemantic technologies, Graz, Austria, September 2006.Morin, E., LeclFre, M., & Trichet, F. (2004). The semantic web in e-recruitment. In The first European symposium of semantic Web (ESWS’2004) (pp. 67–78).Quilan, J. (1993). C4.5: Programs for machine learning. San Mateo, CA, San Francisco, CA, USA: Morgan Kaufmann.Rafter, R., Bradley, K., & Smyt, B. (2000). Automated collaborative filtering applications for online recruitment services. In International conference on adaptivehypermedia and adaptive web-based systems, Trento, Italy (pp. 363–368).Robertson, S., Walker, S., Jones, S., Hancock-Beaulieu, M. M., & Gatford, M. (1994). Okapi at trec-3. NIST Special Publication 500-225: TREC-3, pp. 109–126.Rocchio, J. (1971). Relevance feedback in information retrieval. In The smart system: Experiments in automatic document processing (pp. 313–323). Prentice-Hall.Roche, M., & Kodratoff, Y., 2006. Pruning terminology extracted from a specialized corpus for CV ontology acquisition. In OTM’06, Montpellier, France (pp.1107–1116).Roche, M., & Prince, V. (2008). Evaluation et dTtermination de la pertinence pour des syntagmes candidats a la collocation. In JADT (pp. 1009–1020).Salton, G., & Buckley, C. (1990). Improving retrieval performance by relevance feedback. Journal of the American Society for Information Science, 288–297.Salton, G., & Mcgill, M. J. (1986). Introduction to modern information retrieval. New York, NY, USA: McGraw-Hill Inc.Smyth, B., & Bradley, K. (2003). Personalized information ordering: A case-study in online recruitment. Journal of Knowledge-Based Systems, 269–275.Sparck Jones, K. (1970). Some thoughts on classification for retrieval. Journal of Documentation, 89–101.Sutton, R. S., & Barto, A. G. (1998). Reinforcement learning: An introduction (adaptive computation and machine learning). The MIT Press.Tolksdorf,R.,Mocho,M.,Heese,R.,Oldakowski,R.,&Christian,B.(2006).Semantic-Web-TechnologienimArbeitsvermittlungsprozess.Wirtschaftsinformatik, 17–26.Torres-Moreno, J. M., Velázquez-Morales, P., & Meunier, M. (2001). CORTEX, un algorithme pour la condensation automatique de textes. In ARCo (Vol. 2, pp.365–371).Torres-Moreno, J. M., St-Onge, P.-L., Gagnon, M., El-Bèze, M., & Bellot, P. (2009). Automatic summarization system coupled with a question-answeringsystem (qaas). In CoRR abs/0905.2990.Torres-Moreno, J. M., Velazquez-Morales, P., & Meunier, J. (2002). Condensés de textes par des méthodes numériques. JADT, St Malo, France, 2, 723–734.Viterbi, A. J. (1967). Error bounds for convolutional codes and an asymptotically optimal decoding algorithm. IEEE Transactions on Information Theory, 13,260–269.Yahiaoui, L., Boufaı¨da, Z., & Prié, Y. (2006). Semantic annotation of documents applied to e-recruitment. In SWAP 2006 – Semantic web applications andperspectives. ISSN: 1613-0073.R. Kessler et al. / Information Processing and Management 48 (2012) 1124–11351135

Corp : No corp was found

Discussion : No discussion was found

Conclusion : No conclusion was found

No references was found

