<article>
  <preamble>Das_Martins.pdf</preamble>
  <titre>A Survey on Automatic Text Summarization </titre>
  <auteurs>
    <auteur>Dipanjan Das </auteur>
    <affiliation>No affiliation</affiliation>
    <auteur>Andre F.T </auteur>
    <affiliation>No affiliation</affiliation>
    <auteur>Martins</auteur>
    <affiliation>No affiliation</affiliation>
  </auteurs>
  <abstract>AbstractThe increasing availability of online information has necessitated intensiveresearch in the area of automatic text summarization within the Natural Lan-guage Processing (NLP) community. Over the past half a century, the prob-lem has been addressed from many different perspectives, in varying domainsand using various paradigms. This survey intends to investigate some of themost relevant approaches both in the areas of single-document and multiple-document summarization, giving special emphasis to empirical methods andextractive techniques. Some promising approaches that concentrate on specificdetails of the summarization problem are also discussed. Special attention isdevoted to automatic evaluation of summarization systems, as future researchon summarization is strongly dependent on progress in this area.1</abstract>
  <biblio>ReferencesAmari, S.-I. and Nagaoka, H. (2001). Methods of Information Geometry (Transla-tions of Mathematical Monographs). Oxford University Press. [20]Aone, C., Okurowski, M. E., Gorlinsky, J., and Larsen, B. (1999).A trainablesummarizer with knowledge acquired from robust nlp techniques.In Mani, I.and Maybury, M. T., editors, Advances in Automatic Text Summarization, pages71&#8211;80. MIT Press. [4, 5]Barzilay, R. and Elhadad, M. (1997). Using lexical chains for text summarization.In Proceedings ISTS&#8217;97. [8]Barzilay, R., McKeown, K., and Elhadad, M. (1999).Information fusion in thecontext of multi-document summarization. In Proceedings of ACL &#8217;99. [12, 13,14, 16]Baxendale, P. (1958). Machine-made index for technical literature - an experiment.IBM Journal of Research Development, 2(4):354&#8211;361. [2, 3, 5]Brown, F., Pietra, V. J. D., Pietra, S. A. D., and Mercer, R. L. (1993).Themathematics of statistical machine translation: parameter estimation. Comput.Linguist., 19(2):263&#8211;311. [18]Burges, C., Shaked, T., Renshaw, E., Lazier, A., Deeds, M., Hamilton, N., andHullender, G. (2005). Learning to rank using gradient descent. In ICML &#8217;05:Proceedings of the 22nd international conference on Machine learning, pages 89&#8211;96, New York, NY, USA. ACM. [8]Carbonell, J. and Goldstein, J. (1998). The use of MMR, diversity-based rerankingfor reordering documents and producing summaries. In Proceedings of SIGIR &#8217;98,pages 335&#8211;336, New York, NY, USA. [12, 14, 15]Collins, M. (1999). Head-Driven Statistical Models for Natural Language Parsing.PhD thesis, University of Pennsylvania. [13, 20]Conroy, J. M. and O&#8217;leary, D. P. (2001). Text summarization via hidden markovmodels. In Proceedings of SIGIR &#8217;01, pages 406&#8211;407, New York, NY, USA. [6]Cover, T. and Thomas, J. (1991). Elements of Information Theory. Wiley. [25]Daume III, H. and Marcu, D. (2002). A noisy-channel model for document com-pression. In Proceedings of the Conference of the Association of ComputationalLinguistics (ACL 2002). [20]Daume III, H. and Marcu, D. (2004). A tree-position kernel for document compres-sion. In Proceedings of DUC2004. [20]Edmundson, H. P. (1969). New methods in automatic extracting. Journal of theACM, 16(2):264&#8211;285. [2, 3, 4]28Endres, D. M. and Schindelin, J. E. (2003). A new metric for probability distribu-tions. IEEE Transactions on Information Theory, 49(7):1858&#8211;1860. [26]Evans, D. K. (2005). Similarity-based multilingual multi-document summarization.Technical Report CUCS-014-05, Columbia University. [12, 17]Gous, A. (1999). Spherical subfamily models. [20, 21]Hall, K. and Hofmann, T. (2000).Learning curved multinomial subfamilies fornatural language processing and information retrieval. In Proc. 17th InternationalConf. on Machine Learning, pages 351&#8211;358. Morgan Kaufmann, San Francisco,CA. [20]Hovy, E. and Lin, C. Y. (1999). Automated text summarization in summarist. InMani, I. and Maybury, M. T., editors, Advances in Automatic Text Summariza-tion, pages 81&#8211;94. MIT Press. [17]Knight, K. and Marcu, D. (2000). Statistics-based summarization - step one: Sen-tence compression. In AAAI/IAAI, pages 703&#8211;710. [19]Kupiec, J., Pedersen, J., and Chen, F. (1995). A trainable document summarizer.In Proceedings SIGIR &#8217;95, pages 68&#8211;73, New York, NY, USA. [4]Lebanon, G. (2006). Sequential document representations and simplicial curves. InProceedings of the 22nd Conference on Uncertainty in Artificial Intelligence. [22]Lebanon, G., Mao, Y., and Dillon, J. (2007). The locally weighted bag of wordsframework for document representation. J. Mach. Learn. Res., 8:2405&#8211;2441. [21,22]Lin, C.-Y. (1999). Training a selection function for extraction. In Proceedings ofCIKM &#8217;99, pages 55&#8211;62, New York, NY, USA. [5]Lin, C.-Y. (2004). Rouge: A package for automatic evaluation of summaries. InMarie-Francine Moens, S. S., editor, Text Summarization Branches Out: Pro-ceedings of the ACL-04 Workshop, pages 74&#8211;81, Barcelona, Spain.[8, 23, 24,25]Lin, C.-Y., Cao, G., Gao, J., and Nie, J.-Y. (2006). An information-theoretic ap-proach to automatic evaluation of summaries. In Proceedings of HLT-NAACL&#8217;06, pages 463&#8211;470, Morristown, NJ, USA. [25, 26]Lin, C.-Y. and Hovy, E. (1997). Identifying topics by position. In Proceedings ofthe Fifth conference on Applied natural language processing, pages 283&#8211;290, SanFrancisco, CA, USA. [5]Lin, C.-Y. and Hovy, E. (2002). Manual and automatic evaluation of summaries. InProceedings of the ACL-02 Workshop on Automatic Summarization, pages 45&#8211;51,Morristown, NJ, USA. [23]29Luhn, H. P. (1958). The automatic creation of literature abstracts. IBM Journal ofResearch Development, 2(2):159&#8211;165. [2, 3, 6, 8]Mani, I. and Bloedorn, E. (1997). Multi-document summarization by graph searchand matching. In AAAI/IAAI, pages 622&#8211;628. [15, 16]Marcu, D. (1998a). Improving summarization through rhetorical parsing tuning. InProceedings of The Sixth Workshop on Very Large Corpora, pages 206-215, pages206&#8211;215, Montreal, Canada. [9, 10, 20]Marcu, D. C. (1998b). The rhetorical parsing, summarization, and generation ofnatural language texts. PhD thesis, University of Toronto. Adviser-Graeme Hirst.[10]McKeown, K., Klavans, J., Hatzivassiloglou, V., Barzilay, R., and Eskin, E.(1999). Towards multidocument summarization by reformulation: Progress andprospects. In AAAI/IAAI, pages 453&#8211;460. [11, 12, 13, 14, 16]McKeown, K. R. and Radev, D. R. (1995). Generating summaries of multiple newsarticles. In Proceedings of SIGIR &#8217;95, pages 74&#8211;82, Seattle, Washington. [8, 11,12]Miller, G. A. (1995). Wordnet: a lexical database for english. Commun. ACM,38(11):39&#8211;41. [4, 9]Nenkova, A. (2005). Automatic text summarization of newswire: Lessons learnedfrom the document understanding conference.In Proceedings of AAAI 2005,Pittsburgh, USA. [7]Ono, K., Sumita, K., and Miike, S. (1994). Abstract generation based on rhetoricalstructure extraction. In Proceedings of Coling &#8217;94, pages 344&#8211;348, Morristown,NJ, USA. [9]Osborne, M. (2002). Using maximum entropy for sentence extraction. In Proceedingsof the ACL&#8217;02 Workshop on Automatic Summarization, pages 1&#8211;8, Morristown,NJ, USA. [7]Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J. (2001). Bleu: a method forautomatic evaluation of machine translation. In Proceedings of ACL &#8217;02, pages311&#8211;318, Morristown, NJ, USA. [24]Radev, D. R., Hovy, E., and McKeown, K. (2002). Introduction to the special issueon summarization. Computational Linguistics., 28(4):399&#8211;408. [1, 2]Radev, D. R., Jing, H., and Budzikowska, M. (2000). Centroid-based summarizationof multiple documents: sentence extraction, utility-based evaluation, and userstudies. In NAACL-ANLP 2000 Workshop on Automatic summarization, pages21&#8211;30, Morristown, NJ, USA. [12, 16, 17]30Radev, D. R., Jing, H., Stys, M., and Tam, D. (2004). Centroid-based summariza-tion of multiple documents. Information Processing and Management 40 (2004),40:919&#8211;938. [16, 17]Radev, D. R. and McKeown, K. (1998). Generating natural language summariesfrom multiple on-line sources. Computational Linguistics, 24(3):469&#8211;500. [12]Salton, G. and Buckley, C. (1988). On the use of spreading activation methods inautomatic information. In Proceedings of SIGIR &#8217;88, pages 147&#8211;160, New York,NY, USA. [15]Salton, G., Wong, A., and Yang, A. C. S. (1975). A vector space model for automaticindexing. Communications of the ACM, 18:229&#8211;237. [20]Selman, B., Levesque, H. J., and Mitchell, D. G. (1992). A new method for solvinghard satisfiability problems. In AAAI, pages 440&#8211;446. [11]Svore, K., Vanderwende, L., and Burges, C. (2007). Enhancing single-documentsummarization by combining RankNet and third-party sources. In Proceedings ofthe EMNLP-CoNLL, pages 448&#8211;457. [7, 8]Witbrock, M. J. and Mittal, V. O. (1999). Ultra-summarization (poster abstract):a statistical approach to generating highly condensed non-extractive summaries.In Proceedings of SIGIR &#8217;99, pages 315&#8211;316, New York, NY, USA. [18]31</biblio>
  <conclusion>ConclusionThe rate of information growth due to the World Wide Web has called for a needto develop efficient and accurate summarization systems.Although research onsummarization started about 50 years ago, there is still a long trail to walk inthis field. Over time, attention has drifted from summarizing scientific articles tonews articles, electronic mail messages, advertisements, and blogs. Both abstractiveand extractive approaches have been attempted, depending on the application athand. Usually, abstractive summarization requires heavy machinery for languagegeneration and is difficult to replicate or extend to broader domains. In contrast,simple extraction of sentences have produced satisfactory results in large-scale ap-plications, specially in multi-document summarization. The recent popularity ofeffective newswire summarization systems confirms this claim.This survey emphasizes extractive approaches to summarization using statisti-cal methods.A distinction has been made between single document and multi-document summarization. Since a lot of interesting work is being done far fromthe mainstream research in this field, we have chosen to include a brief discussionon some methods that we found relevant to future research, even if they focus onlyon small details related to a general summarization process and not on building anentire summarization system.Finally, some recent trends in automatic evaluation of summarization systemshave been surveyed.The low inter-annotator agreement figures observed duringmanual evaluations suggest that the future of this research area heavily depends onthe ability to find efficient ways of automatically evaluating these systems and onthe development of measures that are objective enough to be commonly acceptedby the research community.</conclusion>
</article>
