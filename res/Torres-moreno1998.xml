<article>
  <preamble>Torres-moreno1998.pdf</preamble>
  <titre>LETTER </titre>
  <auteur>Scott Fahlman , J. Manuel Torres Moreno , Mirta B. Gordon</auteur>
  <abstract>No abstract was found</abstract>
  <discussion>No discussion was found</discussion>
  <biblio>ReferencesAlpaydin, E. A. I. (1990). Neural models of supervised and unsupervised learning. Un-published doctoral dissertation, Ecole Polytechnique Federale de Lausanne,Switzerland.Biehl, M., &amp; Opper, M. (1991). Tilinglike learning in the parity machine. PhysicalReview A, 44, 6888.Bottou, L., &amp; Vapnik, V. (1992). Local learning algorithms. Neural Computation,4(6), 888&#8211;900.Breiman, L. (1994). Bagging predictors (Tech. Rep. No. 421). Berkeley: Departmentof Statistics, University of California at Berkeley.Breiman, L., Friedman, J. H., Olshen, R. A., &amp; Stone, C. J. (1984). Classificationand regression trees. Monterey, CA: Wadsworth and Brooks/Cole.Denker,J.,Schwartz,D.,Wittner,B.,Solla,S.,Howard,R.,Jackel,L.,&amp;Hopfield,J.(1987). Large automatic learning, rule extraction, and generalization. ComplexSystems, 1, 877&#8211;922.Depenau, J. (1995). Automated design of neural network architecture for classification.Unpublished doctoral dissertation, Computer Science Department, AarhusUniversity.Drucker, H., Schapire, R., &amp; Simard, P. (1993). Improving performance in neu-ral networks using a boosting algorithm. In S. J. Hanson, J. D. Cowan, &amp;C. L. Giles (Eds.), Advances in neural information processing systems, 5 (pp. 42&#8211;49). San Mateo, CA: Morgan Kaufmann.Fahlman, S. E., &amp; Lebiere, C. (1990). The cascade-correlation learning architec-ture. In D. S. Touretzky (Ed.), Advances in neural information processing systems,2 (pp. 524&#8211;532). San Mateo: Morgan Kaufmann.Farrell, K. R., &amp; Mammone, R. J. (1994). Speaker recognition using neural treenetworks. In J. D. Cowan, G. Tesauro, &amp; J. Alspector (Eds.), Advances in NeuralInformation Processing Systems, 6 (pp. 1035&#8211;1042). San Mateo, CA: MorganKaufmann.Frean, M. (1990). The Upstart algorithm: A method for constructing and trainingfeedforward neural networks. Neural Computation, 2(2), 198&#8211;209.Frean, M. (1992). A &#8220;thermal&#8221; perceptron learning rule. Neural Computation, 4(6),946&#8211;957.Friedman, J. H. (1996). On bias, variance, 0/1-loss, and the curse-of-dimensionality(Tech. Rep.) Stanford, CA: Department of Statistics, Stanford University.Fritzke, B. (1994). Supervised learning with growing cell structures. InJ. D. Cowan, G. Tesauro, &amp; J. Alspector (Eds.), Advances in neural informa-tion processing systems, 6 (pp. 255&#8211;262). San Mateo, CA: Morgan Kaufmann.Gallant, S. I. (1986). Optimal linear discriminants. In Proc. 8th. Conf. PatternRecognition, Oct. 28&#8211;31, Paris, vol. 4.Classification Tasks with Binary Units1029Gascuel, O. (1995). Symenu. Collective Paper (Gascuel O. Coordinator) (Tech. Rep.).5emes Journees Nationales du PRC-IA Teknea, Nancy.Geman, S., Bienenstock, E., &amp; Doursat, R. (1992). Neural networks and thebias/variance dilemma. Neural Computation, 4(1), 1&#8211;58.Goodman, R. M., Smyth, P., Higgins, C. M., &amp; Miller, J. W. (1992). Rule-basedneural networks for classification and probability estimation. Neural Compu-tation, 4(6), 781&#8211;804.Gordon, M. B. (1996). A convergence theorem for incremental learning with real-valued inputs. In IEEE International Conference on Neural Networks, pp. 381&#8211;386.Gordon, M. B., &amp; Berchier, D. (1993). Minimerror: A perceptron learning rulethat finds the optimal weights. In M. Verleysen (Ed.), European Symposium onArtificial Neural Networks (pp. 105&#8211;110). Brussels: D Facto.Gordon, M. B., &amp; Grempel, D. (1995). Optimal learning with a temperaturedependent algorithm. Europhysics Letters, 29(3), 257&#8211;262.Gordon, M. B., Peretto, P., &amp; Berchier, D. (1993). Learning algorithms for percep-trons from statistical physics. Journal of Physics I (France), 3, 377&#8211;387.Gorman, R. P., &amp; Sejnowski, T. J. (1988). Analysis of hidden units in a layerednetwork trained to classify sonar targets. Neural Networks, 1, 75&#8211;89.Gyorgyi, G., &amp; Tishby, N. (1990). Statistical theory of learning a rule. InW. K. Theumann &amp; R. Koeberle (Eds.), Neural networks and spin glasses. Sin-gapore: World Scientific.Hoehfeld, M., &amp; Fahlman, S. (1991). Learning with limited numerical precision usingthe cascade correlation algorithm (Tech. Rep. No. CMU-CS-91-130). Pittsburgh:Carnegie Mellon University.Knerr, S., Personnaz, L., &amp; Dreyfus, G. (1990). Single-layer learning revisited: Astepwise procedure for building and training a neural network. In J. Herault&amp; F. Fogelman (Eds.), Neurocomputing, algorithms, architectures and applications(pp. 41&#8211;50). Berlin: Springer-Verlag.Marchand, M., Golea, M., &amp; Ruj&#180;an, P. (1990). A convergence theorem for sequen-tial learning in two-layer perceptrons. Europhysics Letters, 11, 487&#8211;492.Martinez, D., &amp; Esteve, D. (1992). The offset algorithm: Building and learningmethod for multilayer neural networks. Europhysics Letters, 18, 95&#8211;100.Mezard, M., &amp; Nadal, J.-P. (1989). Learning in feedforward layered networks:The Tiling algorithm. J. Phys. A: Math. and Gen., 22, 2191&#8211;2203.Mukhopadhyay, S., Roy, A., Kim, L. S., &amp; Govil, S. (1993). A polynomial time al-gorithm for generating neural networks for pattern classification: Its stabilityproperties and some test results. Neural Computation, 5(2), 317&#8211;330.Nadal, J.-P. (1989). Study of a growth algorithm for a feedforward neural net-work. Int. J. Neur. Syst., 1, 55&#8211;59.Prechelt, L. (1994). PROBEN1&#8212;A set of benchmarks and benchmarking rules for neu-ral network training algorithms (Tech. Rep. No. 21/94). University of Karlsruhe,Faculty of Informatics.Raffin, B., &amp; Gordon, M. B. (1995). Learning and generalization with Minimerror,a temperature dependent learning algorithm. Neural Computation, 7(6), 1206&#8211;1224.1030J. Manuel Torres Moreno and Mirta B. GordonReilly, D. E, Cooper, L. N., &amp; Elbaum, C. (1982). A neural model for categorylearning. Biological Cybernetics, 45, 35&#8211;41.Roy, A., Kim, L., &amp; Mukhopadhyay, S. (1993). A polynomial time algorithmfor the construction and training of a class of multilayer perceptron. NeuralNetworks, 6(1), 535&#8211;545.Sirat, J. A., &amp; Nadal, J.-P. (1990). Neural trees: A new tool for classification.Network, 1, 423&#8211;438.Solla, S. A. (1989). Learning and generalization in layered neural networks: Thecontiguity problem. In L. Personnaz &amp; G. Dreyfus (Eds.), Neural Networksfrom Models to Applications. Paris: I.D.S.E.T.Torres Moreno, J.-M., &amp; Gordon, M. B. (1995). An evolutive architecture coupledwith optimal perceptron learning for classification. In M. Verleysen (Ed.),European Symposium on Artificial Neural Networks. Brussels: D Facto.Torres Moreno, J.-M., &amp; Gordon, M. B. (1998). Characterization of the sonarsignals benchmark. Neural Proc. Letters, 7(1), 1&#8211;4.Trhun, S. B., et al. (1991). The monk&#8217;s problems: A performance comparison of differentlearning algorithms (Tech. Rep. No. CMU-CS-91-197). Pittsburgh: CarnegieMellon University.Vapnik, V. (1992). Principles of risk minimization for learning theory. InJ. E. Moody, S. J. Hanson, &amp; R. P. Lippmann (Eds.), Advances in neural informa-tion processing systems, 4 (pp. 831&#8211;838). San Mateo, CA: Morgan Kaufmann.Verma, B. K., &amp; Mulawka, J. J. (1995). A new algorithm for feedforward neu-ral networks. In M. Verleysen (Ed.), European Symposium on Artificial NeuralNetworks (pp. 359&#8211;364). Brussels: D Facto.Wolberg, W. H., &amp; Mangasarian, O. L. (1990). Multisurface method of patternseparation for medical diagnosis applied to breast cytology. In Proceedings ofthe National Academy of Sciences, USA, 87, 9193&#8211;9196.Received February 13, 1997; accepted September 4, 1997.This article has been cited by:1. C. Citterio, A. Pelagotti, V. Piuri, L. Rocca. 1999. Function approximation-fast-convergence neural approach based on spectralanalysis. IEEE Transactions on Neural Networks 10, 725-740. [CrossRef]2. Andrea Pelagotti, Vincenzo Piuri. 1997. Entropic Analysis and Incremental Synthesis of Multilayered Feedforward NeuralNetworks. International Journal of Neural Systems 08, 647-659. [CrossRef]</biblio>
</article>
