<article>
  <discussion>The departing point for our inquiry into text summarizationevaluation has been recent work on the use of content-basedevaluation metrics that do not rely on human models but thatcompare summary content to input content directly [12]. Wehave some positive and some negative results regarding thedirect use of the full document in content-based evaluation.We have verified that in both generic muti-documentsummarizationandintopic-basedmulti-documentsummarizationinEnglishcorrelationamongmeasuresthat use human models (PYRAMIDS,RESPONSIVENESSand ROUGE) and a measure that does not use models(J S divergence) is strong. We have found that correlationamong the same measures is weak for summarization ofbiographical information and summarization of opinions inblogs. We believe that in these cases content-based measuresshould be considered, in addition to the input document, thesummarization task (i.e. text-based representation, description)to better assess the content of the peers [25], the task being adeterminant factor in the selection of content for the summary.Our multi-lingual experiments in generic single-documentsummarizationconfirmastrongcorrelationamongtheJ S divergence and ROUGE measures. It is worth notingthatROUGEisingeneralthechosenframeworkforpresenting content-based evaluation results in non-Englishsummarization.For the experiments in Spanish, we are conscious that weonly have one model summary to compare with the peers.Nevertheless, these models are the corresponding abstractswritten by the authors. As the experiments in [26] show, theprofessionals of a specialized domain (as, for example, themedical domain) adopt similar strategies to summarize theirtexts and they tend to choose roughly the same content chunksfor their summaries. Previous studies have shown that authorabstracts are able to reformulate content with fidelity [27] andthese abstracts are ideal candidates for comparison purposes.Because of this, the summary of the author of a medical articlecan be taken as reference for summaries evaluation. It is worthnoting that there is still debate on the number of models to beused in summarization evaluation [28]. In the French corpusPISTES, we suspect the situation is similar to the Spanishcase.</discussion>
</article>
