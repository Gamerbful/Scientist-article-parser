<article>
  <preamble>Torres.pdf</preamble>
  <titre>Summary Evaluation with and without References </titre>
  <auteurs>
    <auteur>Juan-Manuel Torres-Moreno </auteur>
    <affiliation>No affiliation</affiliation>
    <auteur>Horacio Saggion </auteur>
    <affiliation>No affiliation</affiliation>
    <auteur>Eric SanJuan </auteur>
    <affiliation>No affiliation</affiliation>
    <auteur>Patricia Vel&#180;azquez-Morales</auteur>
    <affiliation>No affiliation</affiliation>
  </auteurs>
  <abstract>Abstract&#8212;Westudyanewcontent-basedmethodfortheevaluationoftextsummarizationsystemswithouthuman models which is used to produce system rankings.Theresearchiscarriedoutusinganewcontent-basedevaluation framework called FRESA to compute a variety ofdivergences among probability distributions. We apply ourcomparison framework to various well-established content-basedevaluation measures in text summarization such as COVERAGE,RESPONSIVENESS,PYRAMIDSandROUGEstudyingtheirassociations in various text summarization tasks includinggeneric multi-document summarization in English and French,focus-basedmulti-documentsummarizationinEnglishandgeneric single-document summarization in French and Spanish.Index Terms&#8212;Text summarization evaluation, content-basedevaluation measures, divergences.</abstract>
  <biblio>No references was found</biblio>
  <conclusion>VI. CONCLUSIONS AND FUTURE WORKThis paper has presented a series of experiments incontent-based measures that do not rely on the use of modelsummaries for comparison purposes. We have carried outextensive experimentation with different summarization tasksdrawing a clearer picture of tasks where the measures couldbe applied. This paper makes the following contributions:&#8211; We have shown that if we are only interested in rankingsummarization systems according to the content of theirautomatic summaries, there are tasks were models couldbe subtituted by the full document in the computation ofthe J S measure obtaining reliable rankings. However,we have also found that the substitution of modelsby full-documents is not always advisable. We haveSummary Evaluation with and without References17Polibits (42) 2010TABLE IISPEARMAN &#961; OF CONTENT-BASED MEASURES WITH COVERAGE IN DUC&#8217;04 TASK 2MesureCOVERAGEp-valueROUGE-20.79p &lt; 0.0050J S0.68p &lt; 0.0025TABLE IIISPEARMAN &#961; OF CONTENT-BASED MEASURES IN DUC&#8217;04 TASK 5MesureCOVERAGEp-valueRESPONSIVENESSp-valueROUGE-20.78p &lt; 0.0010.44p &lt; 0.05J S0.40p &lt; 0.050-0.18p &lt; 0.25TABLE IVSPEARMAN &#961; OF CONTENT-BASED MEASURES IN TAC&#8217;08 OS TASKMesurePYRAMIDSp-valueRESPONSIVENESSp-valueJ S-0.13p &lt; 0.25-0.14p &lt; 0.25TABLE VSPEARMAN &#961; OF CONTENT-BASED MEASURES WITH ROUGE IN THE Medicina Cl&#180;&#305;nica CORPUS (SPANISH)MesureROUGE-1p-valueROUGE-2p-valueROUGE-SU4p-valueJ S0.56p &lt; 0.1000.46p &lt; 0.1000.45p &lt; 0.200J S20.88p &lt; 0.0010.80p &lt; 0.0020.81p &lt; 0.005J S40.88p &lt; 0.0010.80p &lt; 0.0020.81p &lt; 0.005J SM0.82p &lt; 0.0050.71p &lt; 0.0200.71p &lt; 0.010found weak correlation among different rankings incomplex summarization tasks such as the summarizationof biographical information and the summarization ofopinions.&#8211; We have also carried out large-scale experiments inSpanish and French which show positive medium tostrong correlation among system&#8217;s ranks produced byROUGE and divergence measures that do not use themodel summaries.&#8211; We have also presented a new framework, FRESA, forthe computation of measures based on J S divergence.Following the ROUGE approach, FRESA package useword uni-grams, 2-grams and skip n-grams computingdivergences. This framework will be available to thecommunity for research purposes.Although we have made a number of contributions, this paperleaves many open questions than need to be addressed. Inorder to verify correlation between ROUGE and J S, in theshort term we intend to extend our investigation to otherlanguages such as Portuguese and Chinesse for which wehave access to data and summarization technology. We alsoplan to apply FRESA to the rest of the DUC and TACsummarization tasks, by using several smoothing techniques.As a novel idea, we contemplate the possibility of adaptingthe evaluation framework for the phrase compression task[29], which, to our knowledge, does not have an efficientevaluation measure. The main idea is to calculate J S froman automatically-compressed sentence taking the completesentence by reference. In the long term, we plan to incorporatea representation of the task/topic in the calculation ofmeasures. To carry out these comparisons, however, we aredependent on the existence of references.FRESA will also be used in the new question-answer taskcampaign INEX&#8217;2010 (http://www.inex.otago.ac.nz/tracks/qa/qa.asp) for the evaluation of long answers. This task aimsto answer a question by extraction and agglomeration ofsentences in Wikipedia. This kind of task correspondsto those for which we have found a high correlationamong the measures J Sand evaluation methods withhuman intervention. Moreover, the J S calculation will beamong the summaries produced and a representative set ofrelevant passages from Wikipedia. FRESA will be used tocompare three types of systems, although different tasks: themulti-document summarizer guided by a query, the searchsystems targeted information (focused IR) and the questionanswering systems.ACKNOWLEDGMENTWe are grateful to the Programa Ram&#180;on y Cajal fromMinisterio de Ciencia e Innovaci&#180;on, Spain. This work ispartially supported by: a postdoctoral grant from the NationalProgram for Mobility of Research Human Resources (NationalPlan of Scientific Research, Development and Innovation2008-2011, Ministerio de Ciencia e Innovaci&#180;on, Spain); theresearch project CONACyT, number 82050, and the researchproject PAPIIT-DGAPA (Universidad Nacional Aut&#180;onoma deMexico), number IN403108.Juan-Manuel Torres-Moreno, Horacio Saggion, Iria da Cunha, Eric SanJuan, and Patricia Vel&#225;zquez-Morales18Polibits (42) 2010TABLE VISPEARMAN &#961; OF CONTENT-BASED MEASURES WITH ROUGE IN THE PISTES CORPUS (FRENCH)MesureROUGE-1p-valueROUGE-2p-valueROUGE-SU4p-valueJ S0.70p &lt; 0.0500.73p &lt; 0.050.73p &lt; 0.500J S20.93p &lt; 0.0020.86p &lt; 0.010.86p &lt; 0.005J S40.83p &lt; 0.0200.76p &lt; 0.050.76p &lt; 0.050J SM0.88p &lt; 0.0100.83p &lt; 0.020.83p &lt; 0.010TABLE VIISPEARMAN &#961; OF CONTENT-BASED MEASURES WITH ROUGE IN THE RPM2 CORPUS (FRENCH)MeasureROUGE-1p-valueROUGE-2p-valueROUGE-SU4p-valueJ S0.830p &lt; 0.0020.660p &lt; 0.050.741p &lt; 0.01J S20.800p &lt; 0.0050.590p &lt; 0.050.680p &lt; 0.02J S40.750p &lt; 0.0100.520p &lt; 0.100.620p &lt; 0.05J SM0.850p &lt; 0.0020.640p &lt; 0.050.740p &lt; 0.01REFERENCES[1] I.Mani,G.Klein,D.House,L.Hirschman,T.Firmin,andB. Sundheim, &#8220;Summac: a text summarization evaluation,&#8221; NaturalLanguage Engineering, vol. 8, no. 1, pp. 43&#8211;68, 2002.[2] P. Over, H. Dang, and D. Harman, &#8220;DUC in context,&#8221; IPM, vol. 43,no. 6, pp. 1506&#8211;1520, 2007.[3] Proceedings of the Text Analysis Conference.Gaithesburg, Maryland,USA: NIST, November 17-19 2008.[4] K. Sp&#168;arck Jones and J. Galliers, Evaluating Natural LanguageProcessing Systems, An Analysis and Review, ser. Lecture Notes inComputer Science.Springer, 1996, vol. 1083.[5] R. L. Donaway, K. W. Drummey, and L. A. Mather, &#8220;A comparison ofrankings produced by summarization evaluation measures,&#8221; in NAACLWorkshop on Automatic Summarization, 2000, pp. 69&#8211;78.[6] H. Saggion, D. Radev, S. Teufel, and W. Lam, &#8220;Meta-evaluationof Summaries in a Cross-lingual Environment using Content-basedMetrics,&#8221; in COLING 2002, Taipei, Taiwan, August 2002, pp. 849&#8211;855.[7] D. R. Radev, S. Teufel, H. Saggion, W. Lam, J. Blitzer, H. Qi, A. C&#184; elebi,D. Liu, and E. Dr&#180;abek, &#8220;Evaluation challenges in large-scale documentsummarization,&#8221; in ACL&#8217;03, 2003, pp. 375&#8211;382.[8] K. Papineni, S. Roukos, T. Ward, , and W. J. Zhu, &#8220;BLEU: a methodfor automatic evaluation of machine translation,&#8221; in ACL&#8217;02, 2002, pp.311&#8211;318.[9] K. Pastra and H. Saggion, &#8220;Colouring summaries BLEU,&#8221; in EvaluationInitiatives in Natural Language Processing. Budapest, Hungary: EACL,14 April 2003.[10] C.-Y.Lin,&#8220;ROUGE:APackageforAutomaticEvaluationofSummaries,&#8221; in Text Summarization Branches Out: ACL-04 Workshop,M.-F. Moens and S. Szpakowicz, Eds., Barcelona, July 2004, pp. 74&#8211;81.[11] A. Nenkova and R. J. Passonneau, &#8220;Evaluating Content Selection inSummarization: The Pyramid Method,&#8221; in HLT-NAACL, 2004, pp.145&#8211;152.[12] A. Louis and A. Nenkova, &#8220;Automatically Evaluating Content Selectionin Summarization without Human Models,&#8221; in Empirical Methods inNatural Language Processing, Singapore, August 2009, pp. 306&#8211;314.[Online]. Available: http://www.aclweb.org/anthology/D/D09/D09-1032[13] J. Lin, &#8220;Divergence Measures based on the Shannon Entropy,&#8221; IEEETransactions on Information Theory, vol. 37, no. 145-151, 1991.[14] C.-Y. Lin and E. Hovy, &#8220;Automatic Evaluation of Summaries UsingN-gram Co-occurrence Statistics,&#8221; in HLT-NAACL.Morristown, NJ,USA: Association for Computational Linguistics, 2003, pp. 71&#8211;78.[15] C.-Y. Lin, G. Cao, J. Gao, and J.-Y. Nie, &#8220;An information-theoreticapproach to automatic evaluation of summaries,&#8221; in HLT-NAACL,Morristown, USA, 2006, pp. 463&#8211;470.[16] S. Kullback and R. Leibler, &#8220;On information and sufficiency,&#8221; Ann. ofMath. Stat., vol. 22, no. 1, pp. 79&#8211;86, 1951.[17] S. Siegel and N. Castellan, Nonparametric Statistics for the BehavioralSciences.McGraw-Hill, 1998.[18] C. de Loupy, M. Guegan, C. Ayache, S. Seng, and J.-M. Torres-Moreno,&#8220;AFrenchHumanReferenceCorpusformulti-documentssummarizationandsentencecompression,&#8221;inLREC&#8217;10,vol.2,Malta, 2010, p. In press.[19] S. Fernandez, E. SanJuan, and J.-M. Torres-Moreno, &#8220;Textual Energyof Associative Memories: performants applications of Enertex algorithmin text summarization and topic segmentation,&#8221; in MICAI&#8217;07, 2007, pp.861&#8211;871.[20] J.-M.Torres-Moreno,P.Vel&#180;azquez-Morales,andJ.-G.Meunier,&#8220;Condenses de textes par des methodes numeriques,&#8221; in JADT&#8217;02, vol. 2,St Malo, France, 2002, pp. 723&#8211;734.[21] J. Vivaldi, I. da Cunha, J.-M. Torres-Moreno, and P. Vel&#180;azquez-Morales,&#8220;Automaticsummarizationusingterminologicalandsemanticresources,&#8221; in LREC&#8217;10, vol. 2, Malta, 2010, p. In press.[22] J.-M. Torres-Moreno and J. Ramirez, &#8220;REG : un algorithme gloutonapplique au resume automatique de texte,&#8221; in JADT&#8217;10.Rome, 2010,p. In press.[23] V. Yatsko and T. Vishnyakov, &#8220;A method for evaluating modernsystems of automatic text summarization,&#8221; Automatic Documentationand Mathematical Linguistics, vol. 41, no. 3, pp. 93&#8211;103, 2007.[24] C. D. Manning and H. Sch&#168;utze, Foundations of Statistical NaturalLanguage Processing.Cambridge, Massachusetts: The MIT Press,1999.[25] K. Sp&#168;arck Jones, &#8220;Automatic summarising: The state of the art,&#8221; IPM,vol. 43, no. 6, pp. 1449&#8211;1481, 2007.[26] I. da Cunha, L. Wanner, and M. T. Cabre, &#8220;Summarization of specializeddiscourse: The case of medical articles in spanish,&#8221; Terminology, vol. 13,no. 2, pp. 249&#8211;286, 2007.[27] C.-K. Chuah, &#8220;Types of lexical substitution in abstracting,&#8221; in ACLStudent Research Workshop.Toulouse, France: Association forComputational Linguistics, 9-11 July 2001 2001, pp. 49&#8211;54.[28] K. Owkzarzak and H. T. Dang, &#8220;Evaluation of automatic summaries:Metrics under varying data conditions,&#8221; in UCNLG+Sum&#8217;09, Suntec,Singapore, August 2009, pp. 23&#8211;30.[29] K. Knight and D. Marcu, &#8220;Statistics-based summarization-step one:Sentence compression,&#8221; in Proceedings of the National Conference onArtificial Intelligence.Menlo Park, CA; Cambridge, MA; London;AAAI Press; MIT Press; 1999, 2000, pp. 703&#8211;710.Summary Evaluation with and without References19Polibits (42) 2010</conclusion>
</article>
